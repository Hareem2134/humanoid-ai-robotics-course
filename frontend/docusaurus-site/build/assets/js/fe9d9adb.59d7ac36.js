"use strict";(globalThis.webpackChunkdocusaurus_site=globalThis.webpackChunkdocusaurus_site||[]).push([[8895],{1284:(t,e,n)=>{n.r(e),n.d(e,{assets:()=>c,contentTitle:()=>r,default:()=>l,frontMatter:()=>s,metadata:()=>o,toc:()=>d});const o=JSON.parse('{"id":"vla/introduction-to-vla","title":"Introduction to Vision-Language-Action (VLA) Models","description":"Vision-Language-Action (VLA) models are a new class of AI models that can understand and act upon multimodal inputs, including images, text, and speech. These models are at the forefront of AI research and have the potential to revolutionize robotics.","source":"@site/docs/04-vla/01-introduction-to-vla.md","sourceDirName":"04-vla","slug":"/vla/introduction-to-vla","permalink":"/humanoid-ai-robotics-course/docs/vla/introduction-to-vla","draft":false,"unlisted":false,"editUrl":"https://github.com/haree/humanoid-ai-robotics-course/tree/main/docs/04-vla/01-introduction-to-vla.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Introduction to Vision-Language-Action (VLA) Models"},"sidebar":"defaultSidebar","previous":{"title":"Reinforcement Learning for Robotics","permalink":"/humanoid-ai-robotics-course/docs/nvidia-isaac/reinforcement-learning"},"next":{"title":"Humanoid Kinematics and Manipulation","permalink":"/humanoid-ai-robotics-course/docs/vla/humanoid-kinematics"}}');var i=n(4848),a=n(8453);const s={title:"Introduction to Vision-Language-Action (VLA) Models"},r=void 0,c={},d=[];function u(t){const e={p:"p",...(0,a.R)(),...t.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.p,{children:"Vision-Language-Action (VLA) models are a new class of AI models that can understand and act upon multimodal inputs, including images, text, and speech. These models are at the forefront of AI research and have the potential to revolutionize robotics."}),"\n",(0,i.jsx)(e.p,{children:"In this module, we will explore the fundamentals of VLA models and how they can be integrated with humanoid robots to create intelligent and interactive systems."})]})}function l(t={}){const{wrapper:e}={...(0,a.R)(),...t.components};return e?(0,i.jsx)(e,{...t,children:(0,i.jsx)(u,{...t})}):u(t)}},8453:(t,e,n)=>{n.d(e,{R:()=>s,x:()=>r});var o=n(6540);const i={},a=o.createContext(i);function s(t){const e=o.useContext(a);return o.useMemo(function(){return"function"==typeof t?t(e):{...e,...t}},[e,t])}function r(t){let e;return e=t.disableParentContext?"function"==typeof t.components?t.components(i):t.components||i:s(t.components),o.createElement(a.Provider,{value:e},t.children)}}}]);